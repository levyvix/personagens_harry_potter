{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_personagem_base = 'https://harrypotter.fandom.com'\n",
    "\n",
    "\n",
    "\n",
    "def get_character_info(url):\n",
    "    \"\"\"Visita a página de um personagem e retorna as informações da cartão de informações\n",
    "\n",
    "    Args:\n",
    "        url (str): o link do site do personagem\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: linha com as informações do personagem\n",
    "    \"\"\"\n",
    "\n",
    "    response = requests.get(url)\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    nome = soup.select(\n",
    "        'h2.pi-item.pi-item-spacing.pi-title.pi-secondary-background')[0].text\n",
    "    columns = soup.select('h3.pi-data-label.pi-secondary-font')\n",
    "    infos=[]\n",
    "    for el in soup.select('div.pi-data-value.pi-font'):\n",
    "\n",
    "        # if its a list then put a comma between each element\n",
    "        if len(el.select('li')) > 0:\n",
    "            infos.append(', '.join([li.text for li in el.select('li')]))\n",
    "        else:\n",
    "            infos.append(el.text)\n",
    "\n",
    "    result = pd.DataFrame([infos], columns=[el.text for el in columns])\n",
    "    # include name\n",
    "    result = result.assign(Nome=nome)\n",
    "\n",
    "    # name first\n",
    "    result = result[['Nome'] + [el.text for el in columns]]\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def have_banner(response):\n",
    "    \"\"\"Vê se o personagem tem um banner de nascimento na página\n",
    "\n",
    "    Args:\n",
    "        response (str): link do personagem\n",
    "\n",
    "    Returns:\n",
    "        bool: True se o personagem tem um banner de nascimento\n",
    "    \"\"\"\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    columns = soup.select('h3.pi-data-label.pi-secondary-font')\n",
    "    return 'Nascimento' in [c.text for c in columns]\n",
    "\n",
    "\n",
    "def have_informacoes_bibliograficas(response):\n",
    "    \"\"\" Ver se o personagem tem a caixa de informações biográficas\n",
    "\n",
    "    Args:\n",
    "        href (str): link do personagem\n",
    "\n",
    "    Returns:\n",
    "        bool: True se o personagem tem a caixa de informações biográficas\n",
    "    \"\"\"\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    columns = soup.select(\n",
    "        'h2.pi-item.pi-header.pi-secondary-font.pi-item-spacing.pi-secondary-background > center')\n",
    "\n",
    "    return 'Informações biográficas' in [c.text for c in columns]\n",
    "\n",
    "\n",
    "def get_book_info(url):\n",
    "    \"\"\"Visita a página de um livro e retorna as informações da cartão de informações para cada link <a> que estiver na página, \n",
    "        dentro de um parágrafo <p>\n",
    "\n",
    "    Args:\n",
    "        url (str): link da pagina do livro\n",
    "\n",
    "    Returns:\n",
    "        list[str]: lista com os links dos personagens que tem um banner de nascimento ou informações biográficas\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "\n",
    "\n",
    "    links_personagens = []\n",
    "\n",
    "    for a in tqdm(soup.select('div.mw-parser-output > p > a'), total=len(soup.select('div.mw-parser-output > p > a'))):\n",
    "\n",
    "        try:\n",
    "            response = requests.get(url_personagem_base + a['href'])\n",
    "        except:\n",
    "            continue\n",
    "        if have_banner(response) or have_informacoes_bibliograficas(response) and (url_personagem_base + a['href']) not in links_personagens:\n",
    "            links_personagens.append(a['href'])\n",
    "\n",
    "    return list(set([url_personagem_base + link for link in links_personagens]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_livro1 = 'https://harrypotter.fandom.com/pt-br/wiki/Harry_Potter_e_a_Pedra_Filosofal'\n",
    "url_livro2 = 'https://harrypotter.fandom.com/pt-br/wiki/Harry_Potter_e_a_C%C3%A2mara_Secreta'\n",
    "url_livro3 = 'https://harrypotter.fandom.com/pt-br/wiki/Harry_Potter_e_o_Prisioneiro_de_Azkaban'\n",
    "url_livro4 = 'https://harrypotter.fandom.com/pt-br/wiki/Harry_Potter_e_o_C%C3%A1lice_de_Fogo'\n",
    "url_livro5 = 'https://harrypotter.fandom.com/pt-br/wiki/Harry_Potter_e_a_Ordem_da_F%C3%AAnix'\n",
    "url_livro6 = 'https://harrypotter.fandom.com/pt-br/wiki/Harry_Potter_e_o_Enigma_do_Pr%C3%ADncipe'\n",
    "url_livro7 = 'https://harrypotter.fandom.com/pt-br/wiki/Harry_Potter_e_as_Rel%C3%ADquias_da_Morte'\n",
    "\n",
    "livros = [url_livro1, url_livro2, url_livro3,\n",
    "          url_livro4, url_livro5, url_livro6, url_livro7]\n",
    "\n",
    "href_personagens = []\n",
    "for livro in tqdm(livros):\n",
    "    href_personagens += get_book_info(livro)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to file\n",
    "with open('href_personagens.txt', 'w') as f:\n",
    "    for href in href_personagens:\n",
    "        f.write(href + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read\n",
    "with open('href_personagens.txt', 'r') as f:\n",
    "    # remove \\n\n",
    "    href_personagens = [line[:-1] for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_personagem = []\n",
    "for link_personagem in href_personagens:\n",
    "    try:\n",
    "        dataframes_personagem.append(get_character_info(link_personagem))\n",
    "\n",
    "    except:\n",
    "        print('error')\n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "df_personagens = pd.concat(dataframes_personagem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_personagens\n",
    " .drop_duplicates(subset='Nome')\n",
    " #drop Joanne Rowling\n",
    " .query('Nome != \"Joanne Rowling\"')\n",
    ").to_csv('personagens.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "de",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "29e142fb93695274f703cb27f0e8e753f1cd9d8d69924a5f058f23dd5507b02d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
